import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
from imblearn.over_sampling import SMOTE
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# Load and preprocess data
data = pd.read_csv("RF_imputation_NEW.csv")
data.drop(columns=['deathtime', 'survival_time', 'LOS', 'Unnamed_0', 'V1', 'admittime', 'ID', 'group', 'tLOS', 'subject_id'], inplace=True)
data['outcome'] = data['outcome'].astype(int)
predictor_names = data.columns.difference(['outcome'])

# Function to preprocess data
def preprocess_data(data, predictor_names, random_seed):
    scaler = StandardScaler()
    data[predictor_names] = scaler.fit_transform(data[predictor_names])
    train_data, valid_data = train_test_split(data, test_size=0.3, random_state=random_seed)
    return train_data, valid_data

# Preprocess the data
train_data, valid_data = preprocess_data(data, predictor_names, random_seed=42)

X_train = train_data[predictor_names].values
y_train = train_data['outcome'].values
X_valid = valid_data[predictor_names].values
y_valid = valid_data['outcome'].values

# Apply SMOTE to handle class imbalance
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Function to create model
def create_model(learning_rate=0.01, dropout_rate=0.5):
    model = Sequential()
    model.add(Input(shape=(X_train_resampled.shape[1],)))
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(dropout_rate))
    model.add(Dense(64, activation='relu'))
    model.add(Dropout(dropout_rate))
    model.add(Dense(1, activation='sigmoid'))
    optimizer = Adam(learning_rate=learning_rate)
    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])
    return model

# Cross-validation and hyperparameter tuning
param_grid = {
    'batch_size': [32, 64],
    'epochs': [50, 100],
    'learning_rate': [0.01, 0.001],
    'dropout_rate': [0.5, 0.3]
}

best_auc = 0
best_params = {}

for batch_size in param_grid['batch_size']:
    for epochs in param_grid['epochs']:
        for learning_rate in param_grid['learning_rate']:
            for dropout_rate in param_grid['dropout_rate']:
                kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)
                aucs = []
                for train_idx, val_idx in kfold.split(X_train_resampled, y_train_resampled):
                    model = create_model(learning_rate, dropout_rate)
                    early_stopping = EarlyStopping(monitor='val_loss', patience=10)
                    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001)
                    model.fit(X_train_resampled[train_idx], y_train_resampled[train_idx], 
                              validation_data=(X_train_resampled[val_idx], y_train_resampled[val_idx]),
                              epochs=epochs, batch_size=batch_size, verbose=0,
                              callbacks=[early_stopping, reduce_lr])
                    y_pred_proba = model.predict(X_train_resampled[val_idx])[:, 0]
                    auc = roc_auc_score(y_train_resampled[val_idx], y_pred_proba)
                    aucs.append(auc)
                avg_auc = np.mean(aucs)
                if avg_auc > best_auc:
                    best_auc = avg_auc
                    best_params = {'batch_size': batch_size, 'epochs': epochs, 'learning_rate': learning_rate, 'dropout_rate': dropout_rate}

print(f"Best AUC: {best_auc} using {best_params}")

# Train the final model with the best parameters
final_model = create_model(best_params['learning_rate'], best_params['dropout_rate'])
early_stopping = EarlyStopping(monitor='val_loss', patience=10)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001)
history = final_model.fit(X_train_resampled, y_train_resampled, validation_data=(X_valid, y_valid), 
                          epochs=best_params['epochs'], batch_size=best_params['batch_size'], 
                          verbose=0, callbacks=[early_stopping, reduce_lr])

# Evaluate the model
y_pred_proba = final_model.predict(X_valid)[:, 0]
y_pred = (y_pred_proba > 0.5).astype(int)

print(classification_report(y_valid, y_pred, zero_division=0))

# Calculate AUC for the final model
auc_final = roc_auc_score(y_valid, y_pred_proba)
print(f"Final AUC: {auc_final}")

# Plot ROC curve for the final model
fpr_final, tpr_final, thresholds_final = roc_curve(y_valid, y_pred_proba)
plt.figure()
plt.plot(fpr_final, tpr_final, color='darkorange', lw=2, label=f'ROC curve (area = {auc_final:0.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic for Final Deep Learning Model')
plt.legend(loc="lower right")
plt.show()

























