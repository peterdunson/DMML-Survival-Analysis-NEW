




















import pandas as pd
import numpy as np
import arviz as az
from cmdstanpy import CmdStanModel
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt

# Load the data
data = pd.read_csv("RF_imputation_NEW.csv")

# Drop unnecessary columns
data.drop(columns=['deathtime', 'survival_time', 'LOS', 'Unnamed_0', 'V1', 'admittime', 'ID', 'group', 'tLOS', 'subject_id'], inplace=True)

# Ensure the 'outcome' column is present
if 'outcome' not in data.columns:
    raise ValueError("The 'outcome' column does not exist in the dataframe.")

# Convert the 'outcome' column to integer type
data['outcome'] = data['outcome'].astype(int)

# Normalize the predictors
predictor_names = data.columns.difference(['outcome'])
scaler = StandardScaler()
data[predictor_names] = scaler.fit_transform(data[predictor_names])

# Function to train the model and calculate AUC
def train_and_evaluate(data, predictor_names, stan_file, seed):
    # Split the data into training and validation sets
    train_data, valid_data = train_test_split(data, test_size=0.3, random_state=seed)

    # Prepare data for Stan model
    stan_data = {
        'N': train_data.shape[0],
        'K': len(predictor_names),
        'X': train_data[predictor_names].values,
        'y': train_data['outcome'].values
    }

    # Compile and sample from Stan model
    model = CmdStanModel(stan_file=stan_file)
    fit = model.sample(data=stan_data, seed=seed, chains=4, parallel_chains=4, iter_sampling=2000, iter_warmup=1000)

    # Convert the CmdStanPy output to ArviZ's InferenceData object
    idata = az.from_cmdstanpy(fit)

    # Extract the samples
    beta_samples = idata.posterior['beta'].mean(dim=['chain', 'draw']).values

    # Predict on the training data
    train_preds_prob = 1 / (1 + np.exp(-(np.dot(train_data[predictor_names].values, beta_samples) + idata.posterior['alpha'].mean(dim=['chain', 'draw']).values)))
    train_auc = roc_auc_score(train_data['outcome'], train_preds_prob)

    # Predict on the test data
    test_preds_prob = 1 / (1 + np.exp(-(np.dot(valid_data[predictor_names].values, beta_samples) + idata.posterior['alpha'].mean(dim=['chain', 'draw']).values)))
    test_auc = roc_auc_score(valid_data['outcome'], test_preds_prob)

    return train_auc, test_auc

# Perform multiple data splits and calculate AUCs
num_splits = 6
train_aucs = []
test_aucs = []

for seed in range(num_splits):
    train_auc, test_auc = train_and_evaluate(data, predictor_names, 'logistic_regression_cauchy.stan', seed)
    train_aucs.append(train_auc)
    test_aucs.append(test_auc)

# Plot the AUC values
plt.figure(figsize=(10, 6))
plt.plot(range(num_splits), train_aucs, label='Training AUC', marker='o')
plt.plot(range(num_splits), test_aucs, label='Test AUC', marker='o')
plt.xlabel('Data Split')
plt.ylabel('AUC')
plt.title('Training and Test AUC across Different Data Splits')
plt.legend()
plt.show()

# Print the results
print(f"Mean Training AUC: {np.mean(train_aucs):.4f}")
print(f"Mean Test AUC: {np.mean(test_aucs):.4f}")
print(f"Training AUCs: {train_aucs}")
print(f"Test AUCs: {test_aucs}")






import pandas as pd
import numpy as np
import arviz as az
from cmdstanpy import CmdStanModel
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt

# Load the data
data = pd.read_csv("RF_imputation_NEW.csv")

# Drop unnecessary columns
data.drop(columns=['deathtime', 'survival_time', 'LOS', 'Unnamed_0', 'V1', 'admittime', 'ID', 'group', 'tLOS', 'subject_id', 'COPD', 'CHD_with_no_MI'], inplace=True)

# Ensure the 'outcome' column is present
if 'outcome' not in data.columns:
    raise ValueError("The 'outcome' column does not exist in the dataframe.")

# Convert the 'outcome' column to integer type
data['outcome'] = data['outcome'].astype(int)

# Normalize the predictors
predictor_names = data.columns.difference(['outcome'])
scaler = StandardScaler()
data[predictor_names] = scaler.fit_transform(data[predictor_names])

# Function to train the model and calculate AUC
def train_and_evaluate(data, predictor_names, stan_file, seed):
    # Split the data into training and validation sets
    train_data, valid_data = train_test_split(data, test_size=0.3, random_state=seed)

    # Prepare data for Stan model
    stan_data = {
        'N': train_data.shape[0],
        'K': len(predictor_names),
        'X': train_data[predictor_names].values,
        'y': train_data['outcome'].values
    }

    # Compile and sample from Stan model
    model = CmdStanModel(stan_file=stan_file)
    fit = model.sample(data=stan_data, seed=seed, chains=4, parallel_chains=4, iter_sampling=2000, iter_warmup=1000)

    # Convert the CmdStanPy output to ArviZ's InferenceData object
    idata = az.from_cmdstanpy(fit)

    # Extract the samples
    beta_samples = idata.posterior['beta'].mean(dim=['chain', 'draw']).values

    # Predict on the training data
    train_preds_prob = 1 / (1 + np.exp(-(np.dot(train_data[predictor_names].values, beta_samples) + idata.posterior['alpha'].mean(dim=['chain', 'draw']).values)))
    train_auc = roc_auc_score(train_data['outcome'], train_preds_prob)

    # Predict on the test data
    test_preds_prob = 1 / (1 + np.exp(-(np.dot(valid_data[predictor_names].values, beta_samples) + idata.posterior['alpha'].mean(dim=['chain', 'draw']).values)))
    test_auc = roc_auc_score(valid_data['outcome'], test_preds_prob)

    return train_auc, test_auc

# Perform multiple data splits and calculate AUCs
num_splits = 10
train_aucs = []
test_aucs = []

for seed in range(num_splits):
    train_auc, test_auc = train_and_evaluate(data, predictor_names, 'logistic_regression.stan', seed)
    train_aucs.append(train_auc)
    test_aucs.append(test_auc)

# Plot the AUC values
plt.figure(figsize=(10, 6))
plt.plot(range(num_splits), train_aucs, label='Training AUC', marker='o')
plt.plot(range(num_splits), test_aucs, label='Test AUC', marker='o')
plt.xlabel('Data Split')
plt.ylabel('AUC')
plt.title('Training and Test AUC across Different Data Splits')
plt.legend()
plt.show()

# Print the results
print(f"Mean Training AUC: {np.mean(train_aucs):.4f}")
print(f"Mean Test AUC: {np.mean(test_aucs):.4f}")
print(f"Training AUCs: {train_aucs}")
print(f"Test AUCs: {test_aucs}")






import pandas as pd
import numpy as np
from cmdstanpy import CmdStanModel
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
import arviz as az

# Load and preprocess data
data = pd.read_csv("RF_imputation_NEW.csv")
data.drop(columns=['deathtime', 'survival_time', 'LOS', 'Unnamed_0', 'V1', 'admittime', 'ID', 'group', 'tLOS', 'subject_id'], inplace=True)
data['outcome'] = data['outcome'].astype(int)
predictor_names = data.columns.difference(['outcome'])

# Function to preprocess data
def preprocess_data(data, predictor_names, random_seed):
    scaler = StandardScaler()
    data[predictor_names] = scaler.fit_transform(data[predictor_names])
    train_data, valid_data = train_test_split(data, test_size=0.3, random_state=random_seed)
    return train_data, valid_data

# Function to prepare Stan data
def prepare_stan_data(train_data, predictor_names):
    return {
        'N': train_data.shape[0],
        'K': len(predictor_names),
        'X': train_data[predictor_names].values,
        'y': train_data['outcome'].values
    }

# Function to train and evaluate the model
def train_and_evaluate(train_data, valid_data, predictor_names, stan_file, random_seed):
    stan_data = prepare_stan_data(train_data, predictor_names)
    model = CmdStanModel(stan_file=stan_file)
    fit = model.sample(data=stan_data, seed=random_seed, chains=4, parallel_chains=4, iter_sampling=2000, iter_warmup=1000)
    idata = az.from_cmdstanpy(fit)
    beta_samples = idata.posterior['beta'].mean(dim=['chain', 'draw']).values

    # Predict on the training data
    train_preds_prob = 1 / (1 + np.exp(-(np.dot(train_data[predictor_names].values, beta_samples) + idata.posterior['alpha'].mean(dim=['chain', 'draw']).values)))
    train_auc = roc_auc_score(train_data['outcome'], train_preds_prob)

    # Predict on the test data
    test_preds_prob = 1 / (1 + np.exp(-(np.dot(valid_data[predictor_names].values, beta_samples) + idata.posterior['alpha'].mean(dim=['chain', 'draw']).values)))
    test_auc = roc_auc_score(valid_data['outcome'], test_preds_prob)

    return train_auc, test_auc

# Set a fixed random seed for reproducibility
random_seed = 213

# Preprocess data
train_data, valid_data = preprocess_data(data, predictor_names, random_seed)

# Train and evaluate the model
train_auc, test_auc = train_and_evaluate(train_data, valid_data, predictor_names, 'logistic_regression_cauchy.stan', random_seed)

# Print results
print("Train AUC:", train_auc)
print("Test AUC:", test_auc)






import pandas as pd
import numpy as np
from cmdstanpy import CmdStanModel
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
import arviz as az

# Load and preprocess data
data = pd.read_csv("RF_imputation_NEW.csv")
data.drop(columns=['deathtime', 'survival_time', 'LOS', 'Unnamed_0', 'V1', 'admittime', 'ID', 'group', 'tLOS', 'subject_id', 'COPD', 'CHD_with_no_MI'], inplace=True)
data['outcome'] = data['outcome'].astype(int)
predictor_names = data.columns.difference(['outcome'])

# Function to preprocess data
def preprocess_data(data, predictor_names, random_seed):
    scaler = StandardScaler()
    data[predictor_names] = scaler.fit_transform(data[predictor_names])
    train_data, valid_data = train_test_split(data, test_size=0.3, random_state=random_seed)
    return train_data, valid_data

# Function to prepare Stan data
def prepare_stan_data(train_data, predictor_names):
    return {
        'N': train_data.shape[0],
        'K': len(predictor_names),
        'X': train_data[predictor_names].values,
        'y': train_data['outcome'].values
    }

# Function to train and evaluate the model
def train_and_evaluate(train_data, valid_data, predictor_names, stan_file, random_seed):
    stan_data = prepare_stan_data(train_data, predictor_names)
    model = CmdStanModel(stan_file=stan_file)
    fit = model.sample(data=stan_data, seed=random_seed, chains=4, parallel_chains=4, iter_sampling=2000, iter_warmup=1000)
    idata = az.from_cmdstanpy(fit)
    beta_samples = idata.posterior['beta'].mean(dim=['chain', 'draw']).values

    # Predict on the training data
    train_preds_prob = 1 / (1 + np.exp(-(np.dot(train_data[predictor_names].values, beta_samples) + idata.posterior['alpha'].mean(dim=['chain', 'draw']).values)))
    train_auc = roc_auc_score(train_data['outcome'], train_preds_prob)

    # Predict on the test data
    test_preds_prob = 1 / (1 + np.exp(-(np.dot(valid_data[predictor_names].values, beta_samples) + idata.posterior['alpha'].mean(dim=['chain', 'draw']).values)))
    test_auc = roc_auc_score(valid_data['outcome'], test_preds_prob)

    return train_auc, test_auc

# Set a fixed random seed for reproducibility
random_seed = 213

# Preprocess data
train_data, valid_data = preprocess_data(data, predictor_names, random_seed)

# Train and evaluate the model
train_auc, test_auc = train_and_evaluate(train_data, valid_data, predictor_names, 'logistic_regression.stan', random_seed)

# Print results
print("Train AUC:", train_auc)
print("Test AUC:", test_auc)






import pandas as pd
import numpy as np
from cmdstanpy import CmdStanModel
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
import arviz as az

# Load and preprocess data
data = pd.read_csv("RF_imputation_NEW.csv")
data.drop(columns=['deathtime', 'survival_time', 'LOS', 'Unnamed_0', 'V1', 'admittime', 'ID', 'group', 'tLOS', 'subject_id', 'COPD', 'CHD_with_no_MI'], inplace=True)
data['outcome'] = data['outcome'].astype(int)
predictor_names = data.columns.difference(['outcome'])

# Function to preprocess data
def preprocess_data(data, predictor_names, random_seed):
    scaler = StandardScaler()
    data[predictor_names] = scaler.fit_transform(data[predictor_names])
    train_data, valid_data = train_test_split(data, test_size=0.3, random_state=random_seed)
    return train_data, valid_data

# Function to prepare Stan data
def prepare_stan_data(train_data, predictor_names):
    return {
        'N': train_data.shape[0],
        'K': len(predictor_names),
        'X': train_data[predictor_names].values,
        'y': train_data['outcome'].values
    }

# Function to train and evaluate the model
def train_and_evaluate(train_data, valid_data, predictor_names, stan_file, random_seed):
    stan_data = prepare_stan_data(train_data, predictor_names)
    model = CmdStanModel(stan_file=stan_file)
    fit = model.sample(data=stan_data, seed=random_seed, chains=4, parallel_chains=4, iter_sampling=4000, iter_warmup=2000, adapt_delta=0.95, max_treedepth=15)
    idata = az.from_cmdstanpy(fit)
    beta_samples = idata.posterior['beta_tilde'].mean(dim=['chain', 'draw']).values

    # Predict on the training data
    train_preds_prob = 1 / (1 + np.exp(-(np.dot(train_data[predictor_names].values, beta_samples) + idata.posterior['alpha'].mean(dim=['chain', 'draw']).values)))
    train_auc = roc_auc_score(train_data['outcome'], train_preds_prob)

    # Predict on the test data
    test_preds_prob = 1 / (1 + np.exp(-(np.dot(valid_data[predictor_names].values, beta_samples) + idata.posterior['alpha'].mean(dim=['chain', 'draw']).values)))
    test_auc = roc_auc_score(valid_data['outcome'], test_preds_prob)

    return train_auc, test_auc

# Set a fixed random seed for reproducibility
random_seed = 213

# Preprocess data
train_data, valid_data = preprocess_data(data, predictor_names, random_seed)

# Train and evaluate the model
train_auc, test_auc = train_and_evaluate(train_data, valid_data, predictor_names, 'logistic_regression_horseshoe.stan', random_seed)

# Print results
print("Train AUC:", train_auc)
print("Test AUC:", test_auc)













