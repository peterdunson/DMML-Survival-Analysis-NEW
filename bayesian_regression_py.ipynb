{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d94d9e9-e1ca-4678-a68e-913538777929",
   "metadata": {},
   "source": [
    "## BAYESIAN REGRESSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12088733-5f4c-4d20-b892-2bef895d5d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d155b6-09d3-47b2-827a-4a7a7c231dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bambi as bmb\n",
    "import arviz as az\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('RF_imputation_NEW.csv')\n",
    "\n",
    "# Drop unwanted columns\n",
    "data = data.drop(columns=['deathtime', 'survival_time', 'LOS', 'Unnamed_0', 'V1', 'admittime', 'ID', 'group', 'tLOS', 'subject_id'])\n",
    "\n",
    "# Normalize the predictors\n",
    "predictor_columns = data.columns.difference(['outcome'])\n",
    "data[predictor_columns] = (data[predictor_columns] - data[predictor_columns].mean()) / data[predictor_columns].std()\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data = data.sample(frac=0.7, random_state=213)\n",
    "valid_data = data.drop(train_data.index)\n",
    "\n",
    "# Define and fit the Bayesian logistic regression model using Laplace approximation\n",
    "model = bmb.Model('outcome ~ ' + ' + '.join(predictor_columns), train_data, family='bernoulli')\n",
    "fitted_model = model.fit(inference_method=\"laplace\")\n",
    "\n",
    "# Summarize the model\n",
    "print(fitted_model.summary())\n",
    "\n",
    "# Evaluate the model performance on the training set\n",
    "train_preds_prob = fitted_model.predict(train_data)\n",
    "train_auc_value = roc_auc_score(train_data['outcome'], train_preds_prob)\n",
    "print(\"Train AUC:\", train_auc_value)\n",
    "\n",
    "# Evaluate the model performance on the validation set\n",
    "valid_preds_prob = fitted_model.predict(valid_data)\n",
    "valid_auc_value = roc_auc_score(valid_data['outcome'], valid_preds_prob)\n",
    "print(\"Validation AUC:\", valid_auc_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93b19be-2eda-4a17-82a9-be045729dbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# McMC\n",
    "\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('RF_imputation_NEW.csv')\n",
    "\n",
    "# Drop unwanted columns\n",
    "data = data.drop(columns=['deathtime', 'survival_time', 'LOS', 'Unnamed_0', 'V1', 'admittime', 'ID', 'group', 'tLOS', 'subject_id', 'COPD', 'CHD_with_no_MI'])\n",
    "\n",
    "# Normalize the predictors\n",
    "predictor_columns = data.columns.difference(['outcome'])\n",
    "data[predictor_columns] = (data[predictor_columns] - data[predictor_columns].mean()) / data[predictor_columns].std()\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data = data.sample(frac=0.7, random_state=213)\n",
    "valid_data = data.drop(train_data.index)\n",
    "\n",
    "# Convert to numpy arrays for PyMC3\n",
    "X_train = train_data[predictor_columns].values\n",
    "y_train = train_data['outcome'].values\n",
    "X_valid = valid_data[predictor_columns].values\n",
    "y_valid = valid_data['outcome'].values\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Define the priors\n",
    "    intercept = pm.Normal('Intercept', mu=0, sigma=1)\n",
    "    coefs = pm.Normal('coefs', mu=0, sigma=1, shape=X_train.shape[1])\n",
    "    \n",
    "    # Define the likelihood\n",
    "    linear_combination = intercept + pm.math.dot(X_train, coefs)\n",
    "    probability = pm.Deterministic('p', pm.math.sigmoid(linear_combination))\n",
    "    outcome = pm.Bernoulli('outcome', p=probability, observed=y_train)\n",
    "    \n",
    "    # Sample from the posterior\n",
    "    trace = pm.sample(2000, tune=1000, cores=4, return_inferencedata=False)\n",
    "\n",
    "# Summarize the model\n",
    "summary = pm.summary(trace)\n",
    "print(summary)\n",
    "\n",
    "# Predict on training data\n",
    "with model:\n",
    "    ppc_train = pm.sample_posterior_predictive(trace, var_names=['p'])\n",
    "train_preds_prob = np.mean(ppc_train['p'], axis=0)\n",
    "train_auc_value = roc_auc_score(y_train, train_preds_prob)\n",
    "print(\"Train AUC:\", train_auc_value)\n",
    "\n",
    "# Predict on validation data\n",
    "with model:\n",
    "    ppc_valid = pm.sample_posterior_predictive(trace, var_names=['p'], samples=1000, data=dict(X_train=X_valid))\n",
    "valid_preds_prob = np.mean(ppc_valid['p'], axis=0)\n",
    "valid_auc_value = roc_auc_score(y_valid, valid_preds_prob)\n",
    "print(\"Validation AUC:\", valid_auc_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac4c17b-1326-4613-b909-bd6603937d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5756a62-5d17-45ab-bdd0-0900de6b86cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
