---
title: "bootstrapped_elastic"
author: "Peter"
date: "`r Sys.Date()`"
output: html_document
---


```{r}
# Install and Load Required Packages
library(glmnet)
library(caret)
library(pROC)
library(boot)
library(data.table)

# Load and Preprocess Data
RF_impute_df <- fread("RF_imputation_NEW.csv")
RF_complete_df <- subset(RF_impute_df, select = -c(deathtime, survival_time, LOS, Unnamed_0, V1, admittime, ID, group, tLOS, Anion_gap, subject_id))

# Convert data to data.table
dt <- as.data.table(RF_complete_df)

# Exclude the 'outcome' column and prepare the predictor matrix
if ("outcome" %in% names(dt)) {
  predictor_names <- setdiff(names(dt), "outcome")  # Get names of predictor columns
  x <- as.matrix(dt[, ..predictor_names])  # Exclude the outcome variable
  y <- as.numeric(dt$outcome)  # Convert outcome to numeric
} else {
  stop("The 'outcome' column does not exist in the dataframe.")
}

# Ensure x has at least two columns
if (ncol(x) < 2) {
  stop("The predictor matrix 'x' must have at least two columns.")
}

# Define Elastic Net Bootstrap Function
elastic_net_bootstrap <- function(data, indices) {
  dt_bootstrap <- data[indices, ]
  x_bootstrap <- as.matrix(dt_bootstrap[, ..predictor_names])
  y_bootstrap <- as.numeric(dt_bootstrap$outcome)
  
  cv_fit <- cv.glmnet(x_bootstrap, y_bootstrap, family = "binomial", alpha = 0.5)
  best_lambda <- cv_fit$lambda.min
  model <- glmnet(x_bootstrap, y_bootstrap, family = "binomial", alpha = 0.5, lambda = best_lambda)
  
  return(as.vector(coef(model)))
}

# Run Bootstrapping
set.seed(123)
boot_results <- boot(data = dt, statistic = elastic_net_bootstrap, R = 100)

# Extract and average coefficients across bootstrap samples
avg_coefficients <- apply(boot_results$t, 2, mean)

# Calculate Confidence Intervals
conf_intervals <- lapply(1:ncol(boot_results$t), function(i) boot.ci(boot_results, type = "perc", index = i))

# Split the Data into Training and Test Sets
set.seed(213)
train_idx <- sample(1:nrow(x), size = 0.8 * nrow(x))
x_train <- x[train_idx, ]
y_train <- y[train_idx]
x_test <- x[-train_idx, ]
y_test <- y[-train_idx]

# Train the Final Model Using the Average Coefficients
final_model <- glmnet(x_train, y_train, family = "binomial", alpha = 0.5, lambda = best_lambda)

# Predict on the Test Data
test_predictions <- predict(final_model, newx = x_test, type = "response")

# Calculate AUC
test_roc <- roc(y_test, test_predictions)
cat("Test AUC:", auc(test_roc), "\n")

# Print Confidence Intervals for All Coefficients
for (i in 1:length(conf_intervals)) {
  cat("Confidence interval for coefficient", i - 1, ":\n")
  print(conf_intervals[[i]])
}

```

bayesian methods
```{r}
# Install and Load Required Packages
# Install rstanarm if not already installed

library(rstanarm)
library(data.table)

# Load and Preprocess Data
RF_impute_df <- fread("RF_imputation_NEW.csv")
RF_complete_df <- subset(RF_impute_df, select = -c(deathtime, survival_time, LOS, Unnamed_0, V1, admittime, ID, group, tLOS, Anion_gap, subject_id))

# Convert data to data.table
dt <- as.data.table(RF_complete_df)

# Exclude the 'outcome' column and prepare the predictor matrix
if ("outcome" %in% names(dt)) {
  predictor_names <- setdiff(names(dt), "outcome")  # Get names of predictor columns
  x <- as.matrix(dt[, ..predictor_names])  # Exclude the outcome variable
  y <- as.numeric(dt$outcome)  # Convert outcome to numeric
} else {
  stop("The 'outcome' column does not exist in the dataframe.")
}

# Ensure x has at least two columns
if (ncol(x) < 2) {
  stop("The predictor matrix 'x' must have at least two columns.")
}

# Combine x and y into a data frame for rstanarm
data <- data.frame(outcome = y, x)

# Fit Bayesian Logistic Regression Model with Shrinkage Prior
set.seed(123)
bayesian_model <- stan_glm(outcome ~ ., data = data, family = binomial(link = "logit"),
                           prior = hs(global_scale = 0.5), # horseshoe prior
                           prior_intercept = normal(0, 10),
                           chains = 4, iter = 2000, seed = 123)

# Summarize Posterior Distributions
posterior_summary <- summary(bayesian_model)
print(posterior_summary)

# Extract posterior samples
posterior_samples <- as.data.frame(bayesian_model)

# Print selected features based on non-zero posterior mean
selected_features <- predictor_names[which(posterior_summary$coefficients[-1, "Mean"] != 0)]
cat("Selected Features based on Bayesian Logistic Regression:\n")
print(selected_features)

# Plot the posterior distributions of the coefficients
plot(bayesian_model, prob = 0.95)

```



```{r}
# Install and Load Required Packages
library(glmnet)
library(caret)
library(pROC)
library(boot)
library(data.table)

# Load and Preprocess Data
RF_impute_df <- fread("RF_imputation_NEW.csv")
RF_complete_df <- subset(RF_impute_df, select = -c(deathtime, survival_time, LOS, Unnamed_0, V1, admittime, ID, group, tLOS, subject_id))

# Convert data to data.table
dt <- as.data.table(RF_complete_df)

# Exclude the 'outcome' column and prepare the predictor matrix
if ("outcome" %in% names(dt)) {
  predictor_names <- setdiff(names(dt), "outcome")  # Get names of predictor columns
  x <- as.matrix(dt[, ..predictor_names])  # Exclude the outcome variable
  y <- as.numeric(dt$outcome)  # Convert outcome to numeric
} else {
  stop("The 'outcome' column does not exist in the dataframe.")
}

# Ensure x has at least two columns
if (ncol(x) < 2) {
  stop("The predictor matrix 'x' must have at least two columns.")
}

# Define Elastic Net Bootstrap Function
elastic_net_bootstrap <- function(data, indices) {
  dt_bootstrap <- data[indices, ]
  x_bootstrap <- as.matrix(dt_bootstrap[, ..predictor_names])
  y_bootstrap <- as.numeric(dt_bootstrap$outcome)
  
  cv_fit <- cv.glmnet(x_bootstrap, y_bootstrap, family = "binomial", alpha = 0.5)
  best_lambda <- cv_fit$lambda.min
  model <- glmnet(x_bootstrap, y_bootstrap, family = "binomial", alpha = 0.5, lambda = best_lambda)
  
  return(as.vector(coef(model)))
}

# Run Bootstrapping
set.seed(123)
boot_results <- boot(data = dt, statistic = elastic_net_bootstrap, R = 100)

# Extract and average coefficients across bootstrap samples
avg_coefficients <- apply(boot_results$t, 2, mean)

# Calculate Confidence Intervals
conf_intervals <- lapply(1:ncol(boot_results$t), function(i) boot.ci(boot_results, type = "perc", index = i))

# Split the Data into Training and Test Sets
set.seed(213)
train_idx <- sample(1:nrow(x), size = 0.8 * nrow(x))
x_train <- x[train_idx, ]
y_train <- y[train_idx]
x_test <- x[-train_idx, ]
y_test <- y[-train_idx]

# Train the Final Model Using the Average Coefficients
final_model <- glmnet(x_train, y_train, family = "binomial", alpha = 0.5, lambda = best_lambda)

# Predict on the Test Data
test_predictions <- predict(final_model, newx = x_test, type = "response")

# Calculate AUC
test_roc <- roc(y_test, test_predictions)
cat("Test AUC:", auc(test_roc), "\n")

# Print Confidence Intervals for All Coefficients
for (i in 1:length(conf_intervals)) {
  cat("Confidence interval for coefficient", i - 1, ":\n")
  print(conf_intervals[[i]])
}

# Print Selected Features based on non-zero average coefficients
selected_features <- predictor_names[which(avg_coefficients[-1] != 0)]
cat("Selected Features based on Elastic Net:\n")
print(selected_features)

```




