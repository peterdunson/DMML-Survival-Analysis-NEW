---
title: "logistic_feature_select"
author: "Peter"
date: "`r Sys.Date()`"
output: html_document
---

```{r}
# Load necessary libraries
library(data.table)
library(caret)
library(pROC)
library(glmnet)

# Load the dataset
RF_impute_df <- fread("RF_imputation_NEW.csv")

# Subset the data to exclude unnecessary columns and ensure the outcome variable is included and properly named
RF_complete_df <- subset(RF_impute_df, select = -c(deathtime, survival_time, LOS, Unnamed_0, V1, admittime, ID, group, tLOS))

# Ensure the outcome variable has valid factor levels
RF_complete_df$outcome <- factor(RF_complete_df$outcome, levels = unique(RF_complete_df$outcome))

# Split the dataset into training and test sets
set.seed(403)
train_idx <- createDataPartition(RF_complete_df$outcome, p = 0.8, list = FALSE)
train_data <- RF_complete_df[train_idx, ]
test_data <- RF_complete_df[-train_idx, ]

# Define predictor matrix and outcome variable for training data
x_train <- as.matrix(train_data[, setdiff(names(train_data), "outcome"), with = FALSE])
y_train <- train_data$outcome

# Define predictor matrix and outcome variable for test data
x_test <- as.matrix(test_data[, setdiff(names(test_data), "outcome"), with = FALSE])
y_test <- as.numeric(test_data$outcome) - 1  # Convert outcome to 0 and 1

# Scale the data
preProc <- preProcess(x_train, method = c("center", "scale"))
x_train_scaled <- predict(preProc, x_train)
x_test_scaled <- predict(preProc, x_test)

# Feature Selection using Recursive Feature Elimination (RFE)
ctrl <- rfeControl(functions = rfFuncs, method = "cv", number = 10)
rfe_fit <- rfe(x_train_scaled, y_train, sizes = c(1:5, 10, 15, 20), rfeControl = ctrl)

# Print the results of RFE
print(rfe_fit)
selected_features <- predictors(rfe_fit)
cat("Selected Features:", selected_features, "\n")

# Subset the training and test data to the selected features
x_train_selected <- x_train_scaled[, selected_features, drop = FALSE]
x_test_selected <- x_test_scaled[, selected_features, drop = FALSE]
```



```{r}
# Load necessary libraries
library(data.table)
library(caret)
library(pROC)
library(glmnet)

# Load the dataset
RF_impute_df <- fread("RF_imputation_NEW.csv")

# Subset the data to exclude unnecessary columns and ensure the outcome variable is included and properly named
RF_complete_df <- subset(RF_impute_df, select = -c(deathtime, survival_time, LOS, Unnamed_0, V1, admittime, ID, group, tLOS))

# Ensure valid factor levels for outcome
RF_complete_df$outcome <- factor(make.names(RF_complete_df$outcome))

# Verify levels
levels(RF_complete_df$outcome)

# Split the dataset into training and test sets
set.seed(403)
train_idx <- createDataPartition(RF_complete_df$outcome, p = 0.8, list = FALSE)
train_data <- RF_complete_df[train_idx, ]
test_data <- RF_complete_df[-train_idx, ]

# Define predictor matrix and outcome variable for training data
x_train <- as.matrix(train_data[, setdiff(names(train_data), "outcome"), with = FALSE])
y_train <- train_data$outcome

# Define predictor matrix and outcome variable for test data
x_test <- as.matrix(test_data[, setdiff(names(test_data), "outcome"), with = FALSE])
y_test <- as.numeric(test_data$outcome) - 1  # Convert outcome to 0 and 1

# Scale the data
preProc <- preProcess(x_train, method = c("center", "scale"))
x_train_scaled <- predict(preProc, x_train)
x_test_scaled <- predict(preProc, x_test)

# Feature Selection using Recursive Feature Elimination (RFE)
ctrl <- rfeControl(functions = rfFuncs, method = "cv", number = 10)
rfe_fit <- rfe(x_train_scaled, y_train, sizes = c(1:5, 10, 15, 20), rfeControl = ctrl)

# Print the results of RFE
print(rfe_fit)

# Get selected features
selected_features <- predictors(rfe_fit)
cat("Selected Features:", selected_features, "\n")

# Subset the training and test data to the selected features
x_train_selected <- x_train_scaled[, selected_features, drop = FALSE]
x_test_selected <- x_test_scaled[, selected_features, drop = FALSE]

# Logistic Regression using caret
set.seed(403)
model <- train(
  x = x_train_selected, 
  y = y_train,
  method = "glm",
  family = "binomial",
  trControl = trainControl(method = "cv", number = 10, classProbs = TRUE, summaryFunction = twoClassSummary)
)

# Predict on the test data
pred_probs <- predict(model, newdata = x_test_selected, type = "prob")[,2]
pred_class <- ifelse(pred_probs > 0.5, 1, 0)

# Calculate AUC
roc_obj <- roc(y_test, pred_probs)
auc <- roc_obj$auc
cat("AUC:", auc, "\n")

# Plot ROC curve
plot.roc(roc_obj, main = "ROC Curve (Logistic Regression)")

# Calculate log-loss
log_loss <- function(y_true, y_prob) {
  epsilon <- 1e-15
  y_prob <- pmax(epsilon, pmin(1 - epsilon, y_prob))
  -mean(y_true * log(y_prob) + (1 - y_true) * log(1 - y_prob))
}
log_loss_value <- log_loss(y_test, pred_probs)
cat("Log-loss:", log_loss_value, "\n")

# Confusion matrix with adjusted threshold
conf_matrix <- table(Predicted = pred_class, Actual = y_test)
print(conf_matrix)
```


