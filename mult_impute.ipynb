{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1531bfe0-bc2b-429e-800f-7f56fe95d918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed_0                0\n",
      "ID                       0\n",
      "group                    0\n",
      "outcome                  0\n",
      "age                      0\n",
      "                        ..\n",
      "religion                 0\n",
      "marital_status          27\n",
      "ethnicity                0\n",
      "diagnosis                0\n",
      "hospital_expire_flag     0\n",
      "Length: 66, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "merged_df_NEW = pd.read_csv('merged_df_NEW.csv')\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "# merged_df = pd.read_csv('path_to_your_dataset.csv')\n",
    "\n",
    "# Display a summary of missing values\n",
    "print(merged_df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb22dff7-23c4-41cf-9b07-25c5388acbea",
   "metadata": {},
   "source": [
    "## SINGLE IMPUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d2e6806-770d-4a65-8267-0de80d3f5934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0        ID  group  outcome   age  gendera        BMI  \\\n",
      "0            1.0  100213.0    1.0      0.0  74.0      2.0  26.814570   \n",
      "1            2.0  100449.0    2.0      0.0  87.0      1.0  24.000000   \n",
      "2            3.0  100571.0    1.0      0.0  67.0      1.0  32.284350   \n",
      "3            4.0  100610.0    1.0      0.0  81.0      2.0  26.614580   \n",
      "4            5.0  100660.0    1.0      0.0  75.0      1.0  29.315164   \n",
      "...          ...       ...    ...      ...   ...      ...        ...   \n",
      "1172      1173.0  199859.0    2.0      0.0  55.0      2.0  37.213436   \n",
      "1173      1174.0  199861.0    2.0      0.0  89.0      2.0  27.403770   \n",
      "1174      1175.0  199912.0    2.0      1.0  89.0      2.0  25.080360   \n",
      "1175      1176.0  199925.0    2.0      0.0  86.0      1.0  20.415225   \n",
      "1176      1177.0  199952.0    1.0      0.0  85.0      1.0  33.706539   \n",
      "\n",
      "      hypertensive  atrialfibrillation  CHD with no MI  ...  Anion gap  \\\n",
      "0              1.0                 0.0             0.0  ...  12.222222   \n",
      "1              1.0                 0.0             0.0  ...  10.454545   \n",
      "2              1.0                 0.0             0.0  ...  12.200000   \n",
      "3              1.0                 1.0             0.0  ...  11.888889   \n",
      "4              1.0                 0.0             0.0  ...  12.666667   \n",
      "...            ...                 ...             ...  ...        ...   \n",
      "1172           0.0                 1.0             0.0  ...  16.583333   \n",
      "1173           1.0                 1.0             0.0  ...  13.166667   \n",
      "1174           1.0                 0.0             0.0  ...  20.333333   \n",
      "1175           1.0                 1.0             0.0  ...  13.500000   \n",
      "1176           1.0                 1.0             0.0  ...  17.200000   \n",
      "\n",
      "      Magnesium ion        PH  Bicarbonate  Lactic acid       PCO2    EF  \\\n",
      "0          2.087500  7.373333    29.555556     3.300000  44.333333  55.0   \n",
      "1          2.170000  7.421667    28.090909     1.100000  42.666667  50.0   \n",
      "2          1.930000  7.356429    28.100000     1.512500  38.846154  30.0   \n",
      "3          2.571429  7.360000    28.111111     2.250000  43.000000  55.0   \n",
      "4          2.016667  7.293333    24.833333     1.075736  48.333333  50.0   \n",
      "...             ...       ...          ...          ...        ...   ...   \n",
      "1172       2.227273  7.398000    28.916667     1.000000  46.800000  55.0   \n",
      "1173       2.160000  7.414282    30.833333     1.893427  48.370597  30.0   \n",
      "1174       1.450000  7.272792    15.666667     1.500000  36.759698  30.0   \n",
      "1175       2.050000  7.550000    24.750000     1.650000  28.000000  55.0   \n",
      "1176       1.977778  7.388000    25.000000     1.350000  50.000000  55.0   \n",
      "\n",
      "      subject_id  admittime            deathtime  \n",
      "0        85723.0 1970-01-01                  NaN  \n",
      "1        77177.0 1970-01-01                  NaN  \n",
      "2        99008.0 1970-01-01                  NaN  \n",
      "3        68674.0 1970-01-01                  NaN  \n",
      "4          631.0 1970-01-01                  NaN  \n",
      "...          ...        ...                  ...  \n",
      "1172     99650.0 1970-01-01                  NaN  \n",
      "1173     40293.0 1970-01-01                  NaN  \n",
      "1174     29256.0 1970-01-01  2198-09-20 12:25:00  \n",
      "1175     80825.0 1970-01-01                  NaN  \n",
      "1176     22711.0 1970-01-01                  NaN  \n",
      "\n",
      "[1177 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Assuming merged_df is your DataFrame\n",
    "# merged_df = pd.read_csv('path_to_your_dataset.csv')\n",
    "\n",
    "# Convert datetime columns to numeric (timestamp)\n",
    "merged_df['admittime'] = pd.to_datetime(merged_df['admittime'])\n",
    "merged_df['admittime'] = merged_df['admittime'].astype(int) / 10**9  # Convert datetime to seconds since epoch\n",
    "\n",
    "# Columns to exclude from imputation\n",
    "exclude_columns = ['deathtime']\n",
    "\n",
    "# Separate columns to impute and columns to exclude\n",
    "columns_to_impute = merged_df.drop(columns=exclude_columns).select_dtypes(include=[np.number]).columns\n",
    "excluded_data = merged_df[exclude_columns]\n",
    "\n",
    "# Initialize the Iterative Imputer\n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "\n",
    "# Perform the imputation\n",
    "imputed_data = imputer.fit_transform(merged_df[columns_to_impute])\n",
    "\n",
    "# Convert the imputed data back to a DataFrame\n",
    "imputed_df = pd.DataFrame(imputed_data, columns=columns_to_impute)\n",
    "\n",
    "# Add excluded columns back to the DataFrame\n",
    "imputed_df = pd.concat([imputed_df, excluded_data.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# If you need to convert the datetime back to its original form\n",
    "imputed_df['admittime'] = pd.to_datetime(imputed_df['admittime'] * 10**9)\n",
    "\n",
    "# Display the imputed DataFrame\n",
    "print(imputed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c3f031f-3792-4b2f-b157-e53ad9be9f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the imputed DataFrame to a CSV file\n",
    "# Save the imputed DataFrame to a CSV file in the current working directory\n",
    "imputed_df.to_csv('imputed_dataset.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efed2b15-8ef0-49a1-8714-55c9a0676153",
   "metadata": {},
   "source": [
    "## MULTIPLE IMPUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2d448d5-cd11-40bd-a9f2-91826cebdf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed_0', 'V1', 'ID', 'group', 'outcome', 'age', 'gendera', 'BMI',\n",
      "       'hypertensive', 'atrialfibrillation', 'CHD_with_no_MI', 'diabetes',\n",
      "       'deficiencyanemias', 'depression', 'Hyperlipemia', 'Renal_failure',\n",
      "       'COPD', 'heart_rate', 'Systolic_blood_pressure',\n",
      "       'Diastolic_blood_pressure', 'Respiratory_rate', 'temperature', 'SP_O2',\n",
      "       'Urine_output', 'hematocrit', 'RBC', 'MCH', 'MCHC', 'MCV', 'RDW',\n",
      "       'Leucocyte', 'Platelets', 'Neutrophils', 'Basophils', 'Lymphocyte',\n",
      "       'PT', 'INR', 'NT_proBNP', 'Creatine_kinase', 'Creatinine',\n",
      "       'Urea_nitrogen', 'glucose', 'Blood_potassium', 'Blood_sodium',\n",
      "       'Blood_calcium', 'Chloride', 'Anion_gap', 'Magnesium_ion', 'PH',\n",
      "       'Bicarbonate', 'Lactic_acid', 'PCO2', 'EF', 'subject_id', 'admittime',\n",
      "       'dischtime', 'deathtime', 'admission_type', 'admission_location',\n",
      "       'discharge_location', 'insurance', 'language', 'religion',\n",
      "       'marital_status', 'ethnicity', 'diagnosis', 'hospital_expire_flag',\n",
      "       'survival_time', 'comorb_score', 'LOS', 'tLOS'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import miceforest as mf\n",
    "import re\n",
    "\n",
    "# Convert datetime columns to numeric (timestamp)\n",
    "merged_df_NEW['admittime'] = pd.to_datetime(merged_df_NEW['admittime'])\n",
    "merged_df_NEW['admittime'] = merged_df_NEW['admittime'].astype(int) / 10**9  # Convert datetime to seconds since epoch\n",
    "\n",
    "# Clean column names to remove special characters\n",
    "cleaned_columns = [re.sub(r'\\W+', '_', col) for col in merged_df_NEW.columns]\n",
    "merged_df_NEW.columns = cleaned_columns\n",
    "\n",
    "# Check the column names\n",
    "print(merged_df_NEW.columns)\n",
    "\n",
    "# Columns to exclude from imputation\n",
    "exclude_columns = ['survival_time', 'deathtime', 'LOS']\n",
    "\n",
    "# Ensure exclude_columns exist in the DataFrame\n",
    "exclude_columns = [col for col in exclude_columns if col in merged_df_NEW.columns]\n",
    "\n",
    "# Separate columns to impute and columns to exclude\n",
    "columns_to_impute = merged_df_NEW.drop(columns=exclude_columns).select_dtypes(include=[np.number]).columns\n",
    "data_to_impute = merged_df_NEW[columns_to_impute]\n",
    "\n",
    "# Initialize the KernelDataSet\n",
    "kernel = mf.ImputationKernel(\n",
    "    data=data_to_impute,\n",
    "    save_all_iterations=True,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# Perform multiple imputation with 5 imputations\n",
    "kernel.mice(30)\n",
    "\n",
    "# Extract the completed data from the first imputation\n",
    "completed_data = kernel.complete_data(0)\n",
    "\n",
    "# Combine the imputed data with the excluded columns\n",
    "imputed_df_NEW = pd.concat([completed_data, merged_df_NEW[exclude_columns].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# If you need to convert the datetime back to its original form\n",
    "imputed_df_NEW['admittime'] = pd.to_datetime(imputed_df_NEW['admittime'] * 10**9)\n",
    "\n",
    "# Save the imputed DataFrame to a CSV file\n",
    "imputed_df_NEW.to_csv('multiple_imputation_NEW.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c69d4eb-31d4-4fa5-9d79-280496368e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86809b37-8874-4136-a00a-4cc299b0a4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.0854518609862387\n",
      "Predicted values: [-3.39656071  0.04747127  3.53496476  8.75013829  2.28469933 -2.35298842\n",
      " -5.93260792 -2.06401683  8.08302764 -2.93982082 -2.74377608 -1.74395294\n",
      "  0.98950967 -0.9228023   0.47497881 -2.55150005 -2.55150005 -3.65759875\n",
      " -2.53249913  2.34343668]\n",
      "True values: [-3.73717324  0.22318728  4.74777781  8.10951534  2.83100725 -4.26883568\n",
      " -6.64197059 -0.11434078  9.42139441 -2.20757763 -3.05509498  0.97549574\n",
      " -0.81063972 -0.70351124  1.26090744 -4.16054858 -2.86870112 -6.80797112\n",
      " -3.54898048  4.35184529]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Example data\n",
    "np.random.seed(0)\n",
    "X = np.random.randn(100, 2)  # 100 samples, 2 predictors\n",
    "y = X[:, 0] * 3 + X[:, 1] * 2 + np.random.randn(100)  # True relationship with some noise\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Initialize KNN regressor with k=3\n",
    "knn = KNeighborsRegressor(n_neighbors=3)\n",
    "\n",
    "# Fit the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Predicted values:\", y_pred)\n",
    "print(\"True values:\", y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4a1a1f-c82b-4ce2-830a-25d7b22d329c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
