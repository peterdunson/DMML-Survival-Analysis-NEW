---
title: "deep_learning"
author: "Peter"
date: "`r Sys.Date()`"
output: html_document
---


```{r}
# Load necessary libraries
library(data.table)
library(caret)
library(pROC)
library(keras)

# Load the dataset
RF_impute_df <- fread("RF_imputation_NEW.csv")

# Subset the data to exclude unnecessary columns and ensure the outcome variable is included and properly named
RF_complete_df <- subset(RF_impute_df, select = -c(deathtime, survival_time, LOS, Unnamed_0, V1, admittime, ID, group, tLOS))

# Ensure valid factor levels for outcome
RF_complete_df$outcome <- factor(make.names(RF_complete_df$outcome))

# Verify levels
levels(RF_complete_df$outcome)

# Split the dataset into training and test sets
set.seed(403)
train_idx <- createDataPartition(RF_complete_df$outcome, p = 0.8, list = FALSE)
train_data <- RF_complete_df[train_idx, ]
test_data <- RF_complete_df[-train_idx, ]

# Define predictor matrix and outcome variable for training data
x_train <- as.matrix(train_data[, setdiff(names(train_data), "outcome"), with = FALSE])
y_train <- as.numeric(train_data$outcome) - 1  # Convert outcome to 0 and 1

# Define predictor matrix and outcome variable for test data
x_test <- as.matrix(test_data[, setdiff(names(test_data), "outcome"), with = FALSE])
y_test <- as.numeric(test_data$outcome) - 1  # Convert outcome to 0 and 1

# Normalize the data
x_train <- scale(x_train)
x_test <- scale(x_test)

# Convert labels to categorical one-hot encoding
y_train_cat <- to_categorical(y_train, num_classes = 2)
y_test_cat <- to_categorical(y_test, num_classes = 2)

# Build the neural network model
model <- keras_model_sequential() %>%
  layer_dense(units = 64, activation = 'relu', input_shape = ncol(x_train)) %>%
  layer_dropout(rate = 0.4) %>%
  layer_dense(units = 32, activation = 'relu') %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units = 16, activation = 'relu') %>%
  layer_dropout(rate = 0.2) %>%
  layer_dense(units = 2, activation = 'softmax')

# Compile the model
model %>% compile(
  loss = 'binary_crossentropy',
  optimizer = optimizer_adam(),
  metrics = c('accuracy')
)

# Train the model
history <- model %>% fit(
  x_train, y_train_cat,
  epochs = 100,
  batch_size = 32,
  validation_split = 0.2,
  callbacks = list(
    callback_early_stopping(patience = 10, restore_best_weights = TRUE)
  )
)

# Evaluate the model on the test data
results <- model %>% evaluate(x_test, y_test_cat)
cat('Test loss:', results$loss, "\n")
cat('Test accuracy:', results$accuracy, "\n")

# Predict on the test data
pred_probs <- model %>% predict(x_test)
pred_class <- ifelse(pred_probs[,2] > 0.5, 1, 0)

# Calculate AUC
roc_obj <- roc(y_test, pred_probs[,2])
auc <- roc_obj$auc
cat("AUC:", auc, "\n")

# Plot ROC curve
plot.roc(roc_obj, main = "ROC Curve (Deep Learning)")

# Calculate log-loss
log_loss <- function(y_true, y_prob) {
  epsilon <- 1e-15
  y_prob <- pmax(epsilon, pmin(1 - epsilon, y_prob))
  -mean(y_true * log(y_prob) + (1 - y_true) * log(1 - y_prob))
}
log_loss_value <- log_loss(y_test, pred_probs[,2])
cat("Log-loss:", log_loss_value, "\n")

# Confusion matrix with adjusted threshold
conf_matrix <- table(Predicted = pred_class, Actual = y_test)
print(conf_matrix)
```



